{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25616, 15) (25616,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "WINDOW=15\n",
    "\n",
    "def append(a,b):\n",
    "    if b is None:\n",
    "        return a\n",
    "    if a is None:\n",
    "        a=b\n",
    "    else:\n",
    "        a=np.concatenate((a,b))\n",
    "    return a\n",
    "\n",
    "def get_XY():\n",
    "    path = './*.bin'\n",
    "    files = glob.glob(path)\n",
    "    X = None\n",
    "    y = None\n",
    "    \n",
    "    for j in range(len(files)):\n",
    "        f = files[j]\n",
    "        with open(f, 'rb') as fp:\n",
    "            signal = pickle.load(fp)\n",
    "        xi = None\n",
    "        for example in signal:\n",
    "            data = None\n",
    "            for i in range(len(example)-WINDOW):\n",
    "                chunk = np.array(example[i:i+WINDOW])\n",
    "                chunk = chunk[None,:]\n",
    "                data = append(data, chunk)\n",
    "            if(len(example) < WINDOW):\n",
    "                chunk = np.array(example)\n",
    "                rem = WINDOW - len(chunk)\n",
    "                data = np.concatenate((chunk, np.random.choice(chunk, rem)))\n",
    "                data = data[None,:]\n",
    "            xi = append(xi, data)\n",
    "        yi = np.ones(xi.shape[0]) * j\n",
    "        X = append(X, xi)\n",
    "        y = append(y, yi)\n",
    "    \n",
    "    return shuffle(X, y)\n",
    "\n",
    "X,y = get_XY()\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Class Distribution (count)')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "plt.plot()\n",
    "sns.histplot(y)\n",
    "plt.title('Class Distribution (count)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "dev = torch.device('cpu')\n",
    "BATCH_SIZE = 1024\n",
    "BATCH_SIZE_TRAIN = 1024\n",
    "\n",
    "def get_loader(dev, X, y):\n",
    "    print(X.shape)\n",
    "    target = torch.tensor(y)\n",
    "    target = target.type(torch.LongTensor)\n",
    "    data = torch.tensor(X).float()\n",
    "    tensor = torch.utils.data.TensorDataset(data.to(dev), target.to(dev))\n",
    "    loader = torch.utils.data.DataLoader(dataset=tensor, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                                        pin_memory=True)\n",
    "    return loader\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m)==nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        \n",
    "def train_model(curr_model, Loader, epochs=100, verbose=True, rnn=False, lr=.005):\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(curr_model.parameters(), lr=lr)\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    curr_model.apply(init_weights)\n",
    "    \n",
    "    loss_hist=[]\n",
    "    acc_hist=[]\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        running_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for params, labels in Loader:\n",
    "            labels = labels.squeeze().type(torch.LongTensor)\n",
    "            optimizer.zero_grad()\n",
    "            prediction = curr_model(params.to(dev))\n",
    "            class_preds = torch.argmax(prediction, dim=1)\n",
    "            correct += torch.sum(class_preds == labels)\n",
    "            loss = loss_func(prediction, labels)\n",
    "            total += labels.shape[0]\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        loss = running_loss/len(Loader)\n",
    "        acc = correct / total\n",
    "        loss_hist.append(loss)\n",
    "        acc_hist.append(acc)\n",
    "        if verbose and (e%20==0 or e==epochs-1):\n",
    "            print(f'EPOCH:{e}')\n",
    "            print(f'  Training loss: {loss}')\n",
    "            print(f'  Accuracy: {acc}')\n",
    "    return [acc_hist, loss_hist]\n",
    "                  \n",
    "def get_acc(Loader, model, dev):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for params, labels in Loader:\n",
    "            labels = labels.squeeze().type(torch.LongTensor)\n",
    "            preds = model(params.to(dev))\n",
    "            class_preds = torch.argmax(preds, dim=1)\n",
    "            correct += torch.sum(class_preds == labels)\n",
    "            total += len(labels)\n",
    "    return correct/total\n",
    "\n",
    "def get_predictions(Loader, model, dev):\n",
    "    model.eval()\n",
    "    y = None\n",
    "    with torch.no_grad():\n",
    "        for params, labels in Loader:\n",
    "            preds = model(params.to(dev))\n",
    "            class_preds = torch.argmax(preds, dim=1)\n",
    "            preds = class_preds.detach().cpu().numpy()\n",
    "            y = append(y, preds)\n",
    "    return y\n",
    "\n",
    "class LinearModule(nn.Module):\n",
    "    def __init__(self, in_nodes=5, out_nodes=5, dropout=.2):\n",
    "        super(LinearModule, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.lin = nn.Linear(in_nodes, out_nodes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.lin(x))\n",
    "        return F.dropout(x, self.dropout)\n",
    "    \n",
    "class ANN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, nodes=10, dropout=.2, total_layers=2):\n",
    "        super(ANN, self).__init__()\n",
    "        self.nodes = nodes\n",
    "        self.drp = dropout\n",
    "        self.input_dim = input_dim\n",
    "        self.total_layers = total_layers\n",
    "        self.output_dim = output_dim\n",
    "        self.buildModel()\n",
    "        \n",
    "    def buildModel(self):\n",
    "        lin1 = LinearModule(self.input_dim, self.nodes, self.drp)\n",
    "        self.lin_out = nn.Linear(self.nodes, self.output_dim)\n",
    "        self.lins = nn.ModuleList([lin1])\n",
    "        for i in range(self.total_layers-1):\n",
    "            self.lins.append(LinearModule(self.nodes,self.nodes,self.drp))\n",
    "            \n",
    "    def forward(self, x):\n",
    "        for i, l in enumerate(self.lins):\n",
    "            x = l(x)\n",
    "        x = self.lin_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25616, 15)\n",
      "EPOCH:0\n",
      "  Training loss: 1.6080253995381868\n",
      "  Accuracy: 0.4207916855812073\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-c7a9aaa44bd2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mANN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWINDOW\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-18-7e1dd6a3abb7>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(curr_model, Loader, epochs, verbose, rnn, lr)\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mLoader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'numpy'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'string_'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loader = get_loader(dev, X, y)\n",
    "\n",
    "model = ANN(WINDOW,5,100,.2,5)\n",
    "hist = train_model(model, loader, 100, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_dim, layers):\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        self.hidden_dim= hidden_dim\n",
    "        self.layers=layers\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_dim, hidden_size=hidden_dim,\n",
    "                            num_layers=layers, batch_first=True)\n",
    "        self.lin = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        batch_size = x.size(0)\n",
    "        state = self.init_hidden(batch_size)\n",
    "\n",
    "        out, state = self.lstm(x.view(len(x) ,1, -1), state)\n",
    "        out = out.contiguous().view(-1, self.hidden_dim)\n",
    "        out = self.lin(out)\n",
    "        return out\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.layers, batch_size, self.hidden_dim)\n",
    "        cell = torch.zeros(self.layers, batch_size, self.hidden_dim)\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30980, 7)\n",
      "EPOCH:0\n",
      "  Training loss: 1.5458008627737723\n",
      "  Accuracy: 0.34189799427986145\n",
      "EPOCH:20\n",
      "  Training loss: 1.334151591024091\n",
      "  Accuracy: 0.4334409236907959\n",
      "EPOCH:40\n",
      "  Training loss: 1.3224576673200052\n",
      "  Accuracy: 0.4368624985218048\n",
      "EPOCH:60\n",
      "  Training loss: 1.3175366078653643\n",
      "  Accuracy: 0.4378308653831482\n",
      "EPOCH:80\n",
      "  Training loss: 1.3121078552738312\n",
      "  Accuracy: 0.43576499819755554\n",
      "EPOCH:99\n",
      "  Training loss: 1.2892811682916456\n",
      "  Accuracy: 0.4507424235343933\n"
     ]
    }
   ],
   "source": [
    "loader = get_loader(dev, X, y)\n",
    "model = LSTM(WINDOW,5,5,2)\n",
    "hist = train_model(model, loader, 100, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, conv_dim):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(conv_dim, 64, 9, padding=5)\n",
    "        self.conv2 = nn.Conv1d(64, 32, 7, padding=3)\n",
    "        self.conv3 = nn.Conv1d(32, 64, 7, padding=3)\n",
    "        self.conv4 = nn.Conv1d(64, 32, 5, padding=2)\n",
    "        self.conv5 = nn.Conv1d(32, 64, 5, padding=2)\n",
    "        self.conv6 = nn.Conv1d(64, 32, 3, padding=1)\n",
    "        self.conv7 = nn.Conv1d(32, 64, 3, padding=1)\n",
    "        self.conv8 = nn.Conv1d(64, 5, 3)\n",
    "        \n",
    "        self.flat = nn.Flatten()\n",
    "        self.dense = nn.Linear((WINDOW)*5, 5)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        residual = out\n",
    "        out = self.conv2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv3(out)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        residual = out\n",
    "        \n",
    "        out = self.conv4(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv5(out)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        residual = out\n",
    "        \n",
    "        out = self.conv6(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv7(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv8(out)\n",
    "        \n",
    "        out = self.flat(out)\n",
    "        out, self.dense(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28700, 1, 10)\n",
      "EPOCH:0\n",
      "  Training loss: 1.9996077315560703\n",
      "  Accuracy: 0.3558885157108307\n",
      "EPOCH:20\n",
      "  Training loss: 1.162961731696951\n",
      "  Accuracy: 0.5143554210662842\n",
      "EPOCH:40\n",
      "  Training loss: 1.0968344725411514\n",
      "  Accuracy: 0.5330662131309509\n",
      "EPOCH:60\n",
      "  Training loss: 1.0506199053649246\n",
      "  Accuracy: 0.5515679717063904\n",
      "EPOCH:80\n",
      "  Training loss: 1.0271060179019798\n",
      "  Accuracy: 0.5629616975784302\n",
      "EPOCH:100\n",
      "  Training loss: 0.9826560010170114\n",
      "  Accuracy: 0.5742856860160828\n",
      "EPOCH:120\n",
      "  Training loss: 0.9675571497144371\n",
      "  Accuracy: 0.5806968808174133\n",
      "EPOCH:140\n",
      "  Training loss: 0.9369249266797098\n",
      "  Accuracy: 0.5953658819198608\n",
      "EPOCH:160\n",
      "  Training loss: 0.9299398249593275\n",
      "  Accuracy: 0.5978397130966187\n",
      "EPOCH:180\n",
      "  Training loss: 0.8958633336527594\n",
      "  Accuracy: 0.6108362078666687\n",
      "EPOCH:200\n",
      "  Training loss: 0.8890607444376781\n",
      "  Accuracy: 0.6116724610328674\n",
      "EPOCH:220\n",
      "  Training loss: 0.887306677884069\n",
      "  Accuracy: 0.6127177476882935\n",
      "EPOCH:240\n",
      "  Training loss: 0.8696528226137161\n",
      "  Accuracy: 0.6187804937362671\n",
      "EPOCH:260\n",
      "  Training loss: 0.8370633400205908\n",
      "  Accuracy: 0.6341115236282349\n",
      "EPOCH:280\n",
      "  Training loss: 0.829380619114843\n",
      "  Accuracy: 0.6354703903198242\n",
      "EPOCH:299\n",
      "  Training loss: 0.8462309760266337\n",
      "  Accuracy: 0.6277700066566467\n"
     ]
    }
   ],
   "source": [
    "loader = get_loader(dev, X[:,None,:], y)\n",
    "model = CNN(1)\n",
    "hist = train_model(model, loader, 300, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_LSTM(nn.Module):\n",
    "    def __init__(self, conv_dim, input_dim, output_dim, hidden_dim, layers):\n",
    "        super(CNN_LSTM, self).__init__()\n",
    "        \n",
    "        self.embedded_dim = WINDOW\n",
    "        self.layers = layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(conv_dim, 64, 9, padding=5)\n",
    "        self.conv2 = nn.Conv1d(64, 32, 7, padding=3)\n",
    "        self.conv3 = nn.Conv1d(32, 64, 7, padding=3)\n",
    "        self.conv4 = nn.Conv1d(64, 32, 5, padding=2)\n",
    "        self.conv5 = nn.Conv1d(32, 64, 5, padding=2)\n",
    "        self.conv6 = nn.Conv1d(64, 32, 3, padding=1)\n",
    "        self.conv7 = nn.Conv1d(32, 64, 3, padding=1)\n",
    "        self.conv8 = nn.Conv1d(64, 1, 3)\n",
    "        \n",
    "        self.flat = nn.Flatten()\n",
    "        self.lstm = nn.LSTM(input_size=self.embedded_dim, hidden_size=hidden_dim,\n",
    "                            num_layers=layers, batch_first=True)\n",
    "        self.dense = nn.Linear(hidden_dim, 5)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        state = self.init_hidden(batch_size)\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        residual = out\n",
    "        out = self.conv2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv3(out)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        residual = out\n",
    "        \n",
    "        out = self.conv4(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv5(out)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        residual = out\n",
    "        \n",
    "        out = self.conv6(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv7(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv8(out)\n",
    "        \n",
    "        #out = self.flat(out)\n",
    "        out, state = self.lstm(out, state)\n",
    "        out = self.dense(out)\n",
    "        return out.view(out.size(0),-1)\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.zeros(self.layers, batch_size, self.hidden_dim)\n",
    "        cell = torch.zeros(self.layers, batch_size, self.hidden_dim)\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28700, 1, 10)\n",
      "EPOCH:0\n",
      "  Training loss: 1.4222643375396729\n",
      "  Accuracy: 0.41630661487579346\n",
      "EPOCH:20\n",
      "  Training loss: 1.3796735632008519\n",
      "  Accuracy: 0.4404181241989136\n",
      "EPOCH:40\n",
      "  Training loss: 1.3795518957335373\n",
      "  Accuracy: 0.4404181241989136\n",
      "EPOCH:60\n",
      "  Training loss: 1.379414155565459\n",
      "  Accuracy: 0.4404181241989136\n",
      "EPOCH:80\n",
      "  Training loss: 1.3793061642811215\n",
      "  Accuracy: 0.4404181241989136\n",
      "EPOCH:100\n",
      "  Training loss: 1.379237964235503\n",
      "  Accuracy: 0.4404181241989136\n",
      "EPOCH:120\n",
      "  Training loss: 1.3817081122562802\n",
      "  Accuracy: 0.4404181241989136\n",
      "EPOCH:140\n",
      "  Training loss: 1.3789888250416722\n",
      "  Accuracy: 0.4404181241989136\n",
      "EPOCH:160\n",
      "  Training loss: 1.3726030012656902\n",
      "  Accuracy: 0.4417421519756317\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-10ce0ccdec68>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_loader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCNN_LSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWINDOW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-42-17c063d21dfc>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(curr_model, Loader, epochs, verbose, rnn, lr)\u001b[0m\n\u001b[0;32m     43\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0mrunning_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loader = get_loader(dev, X[:,None,:], y)\n",
    "model = CNN_LSTM(1, WINDOW, 5, 25, 2)\n",
    "hist = train_model(model, loader, 100, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'jt' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-c589672e7457>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'jt -t chesterish'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "!jt -t chesterish\n",
    "preds = get_predictions(test_loader, model, dev)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-3e0c2dc7a773>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'preds' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def train_and_test(i, X_l, y_l):\n",
    "    X_train = None\n",
    "    X_test = None\n",
    "    y_train = None\n",
    "    y_test = None\n",
    "    for j in range(len(X_l)):\n",
    "        if i==j:\n",
    "            X_test = X_l[j]\n",
    "            y_test = y_l[j]\n",
    "        else:\n",
    "            X_train = append(X_train, X_l[j])\n",
    "            y_train = append(y_train, y_l[j])\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def cross_val(X, y):\n",
    "    chunk_size = X.shape[0]//5\n",
    "    X_chunks = []\n",
    "    y_chunks = []\n",
    "    for i in range(4):\n",
    "        X_chunks.append(X[i*chunk_size:(i+1)*chunk_size,...])\n",
    "        y_chunks.append(y[i*chunk_size:(i+1)*chunk_size,...])\n",
    "    X_chunks.append(X[(i+1)*chunk_size:,...])\n",
    "    y_chunks.append(y[(i+1)*chunk_size:,...])\n",
    "    \n",
    "    accs = []\n",
    "    for i in range(5):\n",
    "        X_train, X_test, y_train, y_test = train_and_test(i, X_chunks, y_chunks)\n",
    "        train_loader = get_loader(dev, X_train[:,None,:], y_train)\n",
    "        test_loader = get_loader(dev, X_test[:,None,:], y_test)\n",
    "        model = CNN(1)\n",
    "        train_model(model, train_loader, 150, True)\n",
    "        preds = get_predictions(test_loader, model, dev)\n",
    "        acc = get_acc(test_loader, model, dev)\n",
    "        print(acc)\n",
    "        accs.append(acc)\n",
    "        print(classification_report(y_test, preds))\n",
    "    print(accs)\n",
    "    return accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20493, 1, 15)\n",
      "(5123, 1, 15)\n",
      "EPOCH:0\n",
      "  Training loss: 2.4936398438044955\n",
      "  Accuracy: 0.32645294070243835\n",
      "EPOCH:20\n",
      "  Training loss: 1.143779490675245\n",
      "  Accuracy: 0.5206655859947205\n",
      "EPOCH:40\n",
      "  Training loss: 1.0554349252155848\n",
      "  Accuracy: 0.551895797252655\n",
      "EPOCH:60\n",
      "  Training loss: 0.9519035688468388\n",
      "  Accuracy: 0.5875176787376404\n",
      "EPOCH:80\n",
      "  Training loss: 0.9240421837284452\n",
      "  Accuracy: 0.6023032069206238\n",
      "EPOCH:100\n",
      "  Training loss: 0.8272391330628168\n",
      "  Accuracy: 0.6360708475112915\n",
      "EPOCH:120\n",
      "  Training loss: 0.8043849070866903\n",
      "  Accuracy: 0.6428536772727966\n",
      "EPOCH:140\n",
      "  Training loss: 0.775703815477235\n",
      "  Accuracy: 0.6563704609870911\n",
      "EPOCH:149\n",
      "  Training loss: 0.7622901367999259\n",
      "  Accuracy: 0.6632508635520935\n",
      "tensor(0.5655)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.61      0.75      0.67      2347\n",
      "         1.0       0.42      0.19      0.26       322\n",
      "         2.0       0.51      0.58      0.54      1353\n",
      "         3.0       0.39      0.17      0.23       499\n",
      "         4.0       0.61      0.36      0.46       602\n",
      "\n",
      "    accuracy                           0.57      5123\n",
      "   macro avg       0.51      0.41      0.43      5123\n",
      "weighted avg       0.55      0.57      0.54      5123\n",
      "\n",
      "(20493, 1, 15)\n",
      "(5123, 1, 15)\n",
      "EPOCH:0\n",
      "  Training loss: 2.369883066131955\n",
      "  Accuracy: 0.32035329937934875\n",
      "EPOCH:20\n",
      "  Training loss: 1.2034390142985754\n",
      "  Accuracy: 0.49275362491607666\n",
      "EPOCH:40\n",
      "  Training loss: 1.0724484977268038\n",
      "  Accuracy: 0.5463817119598389\n",
      "EPOCH:60\n",
      "  Training loss: 1.0315816288902646\n",
      "  Accuracy: 0.5607768297195435\n",
      "EPOCH:80\n",
      "  Training loss: 0.9151491707279569\n",
      "  Accuracy: 0.6039623022079468\n",
      "EPOCH:100\n",
      "  Training loss: 0.8544693120888301\n",
      "  Accuracy: 0.627092182636261\n",
      "EPOCH:120\n",
      "  Training loss: 0.8511372471139544\n",
      "  Accuracy: 0.630020022392273\n",
      "EPOCH:140\n",
      "  Training loss: 0.7447427333820433\n",
      "  Accuracy: 0.6739374399185181\n",
      "EPOCH:149\n",
      "  Training loss: 0.773239075073174\n",
      "  Accuracy: 0.6586639285087585\n",
      "tensor(0.5530)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.76      0.67      2371\n",
      "         1.0       0.33      0.20      0.25       306\n",
      "         2.0       0.52      0.51      0.52      1426\n",
      "         3.0       0.34      0.16      0.22       446\n",
      "         4.0       0.55      0.29      0.38       574\n",
      "\n",
      "    accuracy                           0.55      5123\n",
      "   macro avg       0.47      0.39      0.41      5123\n",
      "weighted avg       0.53      0.55      0.53      5123\n",
      "\n",
      "(20493, 1, 15)\n",
      "(5123, 1, 15)\n",
      "EPOCH:0\n",
      "  Training loss: 2.400911047345116\n",
      "  Accuracy: 0.33835944533348083\n",
      "EPOCH:20\n",
      "  Training loss: 1.1386680319195701\n",
      "  Accuracy: 0.5173962116241455\n",
      "EPOCH:40\n",
      "  Training loss: 0.9983141110056922\n",
      "  Accuracy: 0.568096399307251\n",
      "EPOCH:60\n",
      "  Training loss: 0.9161185920238495\n",
      "  Accuracy: 0.6017664670944214\n",
      "EPOCH:80\n",
      "  Training loss: 0.8357718189557394\n",
      "  Accuracy: 0.6286537051200867\n",
      "EPOCH:100\n",
      "  Training loss: 0.7879200155536333\n",
      "  Accuracy: 0.6488069295883179\n",
      "EPOCH:120\n",
      "  Training loss: 0.7350697020689646\n",
      "  Accuracy: 0.6731566786766052\n",
      "EPOCH:140\n",
      "  Training loss: 0.7190623503355753\n",
      "  Accuracy: 0.6813545823097229\n",
      "EPOCH:149\n",
      "  Training loss: 0.7439697523202214\n",
      "  Accuracy: 0.6706680059432983\n",
      "tensor(0.5140)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.62      0.62      2300\n",
      "         1.0       0.39      0.33      0.36       321\n",
      "         2.0       0.51      0.44      0.47      1441\n",
      "         3.0       0.28      0.26      0.27       482\n",
      "         4.0       0.39      0.58      0.47       579\n",
      "         5.0       0.00      0.00      0.00         0\n",
      "         6.0       0.00      0.00      0.00         0\n",
      "         7.0       0.00      0.00      0.00         0\n",
      "         8.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.51      5123\n",
      "   macro avg       0.24      0.25      0.24      5123\n",
      "weighted avg       0.52      0.51      0.51      5123\n",
      "\n",
      "(20493, 1, 15)\n",
      "(5123, 1, 15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luke\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH:0\n",
      "  Training loss: 2.184279038792565\n",
      "  Accuracy: 0.33801785111427307\n",
      "EPOCH:20\n",
      "  Training loss: 1.0878873211996896\n",
      "  Accuracy: 0.5444297790527344\n",
      "EPOCH:40\n",
      "  Training loss: 0.9654574422609239\n",
      "  Accuracy: 0.589030385017395\n",
      "EPOCH:60\n",
      "  Training loss: 0.866929924204236\n",
      "  Accuracy: 0.6213828921318054\n",
      "EPOCH:80\n",
      "  Training loss: 0.7744366086664654\n",
      "  Accuracy: 0.6593471169471741\n",
      "EPOCH:100\n",
      "  Training loss: 0.7374096615683465\n",
      "  Accuracy: 0.6762309074401855\n",
      "EPOCH:120\n",
      "  Training loss: 0.6629457949172883\n",
      "  Accuracy: 0.7099009156227112\n",
      "EPOCH:140\n",
      "  Training loss: 0.6010368714729944\n",
      "  Accuracy: 0.7352266907691956\n",
      "EPOCH:149\n",
      "  Training loss: 0.6504952744359062\n",
      "  Accuracy: 0.7120968103408813\n",
      "tensor(0.5626)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.64      0.69      0.66      2320\n",
      "         1.0       0.42      0.22      0.29       343\n",
      "         2.0       0.53      0.54      0.54      1447\n",
      "         3.0       0.32      0.26      0.29       424\n",
      "         4.0       0.51      0.51      0.51       589\n",
      "         5.0       0.00      0.00      0.00         0\n",
      "         6.0       0.00      0.00      0.00         0\n",
      "         7.0       0.00      0.00      0.00         0\n",
      "         8.0       0.00      0.00      0.00         0\n",
      "        11.0       0.00      0.00      0.00         0\n",
      "        12.0       0.00      0.00      0.00         0\n",
      "        13.0       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.56      5123\n",
      "   macro avg       0.20      0.19      0.19      5123\n",
      "weighted avg       0.55      0.56      0.56      5123\n",
      "\n",
      "(20492, 1, 15)\n",
      "(5124, 1, 15)\n",
      "EPOCH:0\n",
      "  Training loss: 2.293829980350676\n",
      "  Accuracy: 0.32398009300231934\n",
      "EPOCH:20\n",
      "  Training loss: 1.1799843368076144\n",
      "  Accuracy: 0.5105894804000854\n",
      "EPOCH:40\n",
      "  Training loss: 1.0741042210942222\n",
      "  Accuracy: 0.5397228002548218\n",
      "EPOCH:60\n",
      "  Training loss: 1.0148336191972096\n",
      "  Accuracy: 0.5604138374328613\n",
      "EPOCH:80\n",
      "  Training loss: 0.9770776757172176\n",
      "  Accuracy: 0.581983208656311\n",
      "EPOCH:100\n",
      "  Training loss: 0.9783272615500859\n",
      "  Accuracy: 0.5805680155754089\n",
      "EPOCH:120\n",
      "  Training loss: 0.91502683645203\n",
      "  Accuracy: 0.6042845845222473\n",
      "EPOCH:140\n",
      "  Training loss: 0.9007578712134134\n",
      "  Accuracy: 0.6095549464225769\n",
      "EPOCH:149\n",
      "  Training loss: 0.8313161532084147\n",
      "  Accuracy: 0.6377610564231873\n",
      "tensor(0.5718)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.74      0.68      2353\n",
      "         1.0       0.38      0.31      0.34       314\n",
      "         2.0       0.53      0.54      0.53      1431\n",
      "         3.0       0.41      0.19      0.26       450\n",
      "         4.0       0.55      0.40      0.46       576\n",
      "\n",
      "    accuracy                           0.57      5124\n",
      "   macro avg       0.50      0.43      0.45      5124\n",
      "weighted avg       0.56      0.57      0.56      5124\n",
      "\n",
      "[tensor(0.5655), tensor(0.5530), tensor(0.5140), tensor(0.5626), tensor(0.5718)]\n"
     ]
    }
   ],
   "source": [
    "accs = cross_val(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55336434"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "  Precision: 0.622\n",
      "  Recall: 0.712\n",
      "  F1: 0.66\n",
      "1\n",
      "  Precision: 0.388\n",
      "  Recall: 0.25\n",
      "  F1: 0.3\n",
      "2\n",
      "  Precision: 0.5200000000000001\n",
      "  Recall: 0.522\n",
      "  F1: 0.5200000000000001\n",
      "3\n",
      "  Precision: 0.348\n",
      "  Recall: 0.20800000000000002\n",
      "  F1: 0.254\n",
      "4\n",
      "  Precision: 0.522\n",
      "  Recall: 0.42800000000000005\n",
      "  F1: 0.45600000000000007\n"
     ]
    }
   ],
   "source": [
    "pre = {0:[.61, .60, .63, .64, .63], 1:[.42, .33, .39, .42, .38], 2:[.51, .52, .51, .53, .53], \n",
    "       3:[.39, .34, .28, .32, .41], 4:[.61, .55, .39, .51, .55]}\n",
    "rec = {0:[.75, .76, .62, .69, .74], 1:[.19, .20, .33, .22, .31], 2:[.58, .51, .44, .54, .54],\n",
    "       3:[.17, .16, .26, .26, .19], 4:[.36, .29, .58, .51, .40]}\n",
    "f1 = {0:[.67, .67, .62, .66, .68], 1:[.26, .25, .36, .29, .34], 2:[.54, .52, .47, .54, .53],\n",
    "      3:[.23, .22, .27, .29, .26], 4:[.46, .38, .47, .51, .46]}\n",
    "\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "    print(f'  Precision: {np.mean(pre[i])}')\n",
    "    print(f'  Recall: {np.mean(rec[i])}')\n",
    "    print(f'  F1: {np.mean(f1[i])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
